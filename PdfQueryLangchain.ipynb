{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsS9n8RqdjEG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBtk_tC8zmC1"
      },
      "source": [
        "## PDF Query Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install PyPDF2 langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v8fCmC-6Q3pP"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_FA1ZERdRLAM"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('/Users/omkar/Downloads/Omkar-Kadam-resume.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q9AeO9cDRqMj"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "yGlxUMl-Rsmy",
        "outputId": "e248b48b-ffc3-457e-b1ba-406a41e1f86b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Summary\\nResults-driven yet Innovative IT professional with strong Problem-Solving, interpersonal, communication skills with\\nanalytical mindset, thriving in fast-paced collaborative environments. Offers 3+ years of experience in developing NLP\\nand machine learning solutions for ﬁnance and HR domains. Expertise includes end-to-end analytical solution design,\\nautomated data pre-processing and Tableau dashboard development, utilizing algorithms, deep learning and natural\\nlanguage processing.\\nSkills\\nTableau, Python, Machine Learning, Clustering, Classiﬁcation techniques, SQL, Linear Regression and Forecasting\\nmodels, Natural Language Processing, Docker, Advanced Analytics, AWS, Statistics, critical Thinking, Statistical Analysis,\\nnosql, git, Databases, GCP, Excel, Advance Excel\\nExperience\\nWorkshop Trainer\\nIndian Institute of Technology Hyderabad • Sangareddy, Telangana 11/2023 - 11/2023\\nDelivered comprehensive sessions on cutting-edge topics including Generative Adversarial Networks (GANs) and\\nGPT models.\\nImplemented a practical approach, empowering students with hands-on experience in utilizing and customizing\\nGPT models to meet the speciﬁc requirements of their projects.\\nFocused on imparting skills in customization, ensuring that participants gained the ability to tailor GPT models to\\naddress unique challenges in their respective projects.\\nTrainer\\nRamachandran International Institute of Management • Pune, Maharashtra 10/2023 - 11/2023\\nConducted Training on Microsoft excel: Basic Excel Skills , Data formatting, Pivot Tables, Connecting to multiple\\ndata sources,visualizations, customization of charts and dashboard designing, Introduction to Tableau chars and\\ndashboarding to PGDM Business Analytics Audience.\\nResponsible to deliver the importance of tools while solving business case studies and dashboarding.\\nData Analyst (Product Development)\\nZingHR • Pune, Maharashtra 03/2022 - 10/2023\\nSpearheaded a Resume Parser project, saving costs and generating revenue. I navigated resource constraints,\\ndesigned architecture, and delivered a product now used by 750+ clients globally.\\nResponsible for Deployment by designing API using Flask and updating the services on docker.\\nIntegrated OpenAI with the the existing platform for Parsing resume which helped improved accuracy percentage\\nfrom 65% to 90%.\\nProposed an NLP based solution to identify duplicate JIRA ticket.\\nSkills used: Text ranking algorithm,entity recognition,Bert,Word2vec,Gensim,Semantic Analysis, OpenAI, Python,\\nSpacy, BERT, NER,AI, Machine Learning, Elastic-search, MongoDB, Flask, API, and Docker.\\nVisiting Faculty\\nMaharashtra institute of Technology • Pune, Maharashtra 08/2019 - 05/2023\\n- 2019:Omkar Kadam\\nkadam.omkar05@gmail.com \\n+91 - 8879891595 \\nPune, MaharashtraDelivering sessions on Microsoft Excel on the following topics: Basic excel, Data formatting, Pivoting, Charts,\\nDashboarding and power-automate for data analysis.\\n- 2021:\\nResponsible for Designing the curriculum for MongoDB, Deep Learning and Matlab for the School of Computer\\nScience.\\nResponsible for designing and Implementing a Project based Learning skills to help imbibe the importance and\\nunderstand the role of persistent system in a Project.\\nSubjects taught : MongoDB , Cloud Services( Google Cloud Platform),Principles of Deep Learning and Introduction\\nto Matlab, Python (core and Advanced), Machine learning (Theory and Practical).\\nData Scientist\\niLink Systems • Pune, Maharashtra 08/2021 - 02/2022\\nPepsiCo\\nCollaborated with a team of 3 to Develop and Deploy Machine learning model using various Clustering\\nTechniques, Regression Models and XGBoost.\\nUtilized DataBricks for Data Transformation and H2o.ai for Model Tuning and Optimization.\\nCreated a comprehensive simulated system showcasing the entire workﬂow, skillfully implemented using Flask\\nand Chart.js.\\nResponsible for Framework shifting (PyTorch to TensorFlow)\\nData Analyst\\nZS Associates • Pune, Maharashtra 03/2021 - 07/2021\\nResponsible for Gathering new requirements for introducing a new module in the existing SAP system.\\nPerforming the feasibility check and communicating the client requirements effectively to the developers.\\nPerforming unit testing on the developed module and documenting the performance analysis.\\nData Science Consultant\\nNaviya Technology • Pune, Maharashtra 09/2020 - 04/2021\\nResponsible for designing end-to-end analytical solution for the existing organizational workﬂow for better\\nDecision making.\\nIntroduced Tableau software to the company and helped them setup and implemented end to end POC to the\\ndecision makers.\\nAnalyze, cleanse and transform data using Python and SQL in-line with business requirements.\\nEducation\\nMsc (Data Science and Big Data Analytics)\\nMIT World Peace University • Pune, Maharashtra 06/2021\\nPublished Research Paper in International Journal of Engineering Research & Technology.\\nMember of Board of Studies - School of Computer Science and Mathematics\\nAdditinal Profiles\\nPublication:\\nTitle : \"A modern approach towards stocks Prediction over Traditional Methods\" Link\\nTableau Proﬁle:\\nTableau Public Proﬁle : Link\\nGitHub: Link LinkedIn : Link\\nCredly: Link\\nLanguagesEnglish, Hindi, Marathi (Mar ā t ̣ h ī )\\nCertifications\\nGoogle Cloud Big Data and Machine Learning Fundamentals - Google Cloud Platform.\\nScalable Machine Learning on Big Data using Apache Spark - IBM\\xa0\\nBusiness Statistics and Analysis Specialization - Rice University\\nBig Data Hadoop Professional - C.M.S IT Services'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VP6ap_PSRt7s"
      },
      "outputs": [
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_text(raw_text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Download embeddings from OpenAI\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m document_search \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_texts(texts, embeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omkar/Documents/openai/ChatPDF/PdfQueryLangchain.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquestion_answering\u001b[39;00m \u001b[39mimport\u001b[39;00m load_qa_chain\n",
            "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
          ]
        }
      ],
      "source": [
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)\n",
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()\n",
        "document_search = FAISS.from_texts(texts, embeddings)\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
        "\n",
        "# query = \" what is session 2 consist of\"\n",
        "# docs = document_search.similarity_search(query)\n",
        "# chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9GLXwH1SVOe",
        "outputId": "4d041f5d-ba38-4821-a19c-c0cdb2f56676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Summary\\nResults-driven yet Innovative IT professional with strong Problem-Solving, interpersonal, communication skills with\\nanalytical mindset, thriving in fast-paced collaborative environments. Offers 3+ years of experience in developing NLP\\nand machine learning solutions for ﬁnance and HR domains. Expertise includes end-to-end analytical solution design,\\nautomated data pre-processing and Tableau dashboard development, utilizing algorithms, deep learning and natural\\nlanguage processing.\\nSkills\\nTableau, Python, Machine Learning, Clustering, Classiﬁcation techniques, SQL, Linear Regression and Forecasting\\nmodels, Natural Language Processing, Docker, Advanced Analytics, AWS, Statistics, critical Thinking, Statistical Analysis,\\nnosql, git, Databases, GCP, Excel, Advance Excel\\nExperience',\n",
              " 'models, Natural Language Processing, Docker, Advanced Analytics, AWS, Statistics, critical Thinking, Statistical Analysis,\\nnosql, git, Databases, GCP, Excel, Advance Excel\\nExperience\\nWorkshop Trainer\\nIndian Institute of Technology Hyderabad • Sangareddy, Telangana 11/2023 - 11/2023\\nDelivered comprehensive sessions on cutting-edge topics including Generative Adversarial Networks (GANs) and\\nGPT models.\\nImplemented a practical approach, empowering students with hands-on experience in utilizing and customizing\\nGPT models to meet the speciﬁc requirements of their projects.\\nFocused on imparting skills in customization, ensuring that participants gained the ability to tailor GPT models to\\naddress unique challenges in their respective projects.\\nTrainer',\n",
              " 'Focused on imparting skills in customization, ensuring that participants gained the ability to tailor GPT models to\\naddress unique challenges in their respective projects.\\nTrainer\\nRamachandran International Institute of Management • Pune, Maharashtra 10/2023 - 11/2023\\nConducted Training on Microsoft excel: Basic Excel Skills , Data formatting, Pivot Tables, Connecting to multiple\\ndata sources,visualizations, customization of charts and dashboard designing, Introduction to Tableau chars and\\ndashboarding to PGDM Business Analytics Audience.\\nResponsible to deliver the importance of tools while solving business case studies and dashboarding.\\nData Analyst (Product Development)\\nZingHR • Pune, Maharashtra 03/2022 - 10/2023',\n",
              " 'Responsible to deliver the importance of tools while solving business case studies and dashboarding.\\nData Analyst (Product Development)\\nZingHR • Pune, Maharashtra 03/2022 - 10/2023\\nSpearheaded a Resume Parser project, saving costs and generating revenue. I navigated resource constraints,\\ndesigned architecture, and delivered a product now used by 750+ clients globally.\\nResponsible for Deployment by designing API using Flask and updating the services on docker.\\nIntegrated OpenAI with the the existing platform for Parsing resume which helped improved accuracy percentage\\nfrom 65% to 90%.\\nProposed an NLP based solution to identify duplicate JIRA ticket.\\nSkills used: Text ranking algorithm,entity recognition,Bert,Word2vec,Gensim,Semantic Analysis, OpenAI, Python,',\n",
              " 'from 65% to 90%.\\nProposed an NLP based solution to identify duplicate JIRA ticket.\\nSkills used: Text ranking algorithm,entity recognition,Bert,Word2vec,Gensim,Semantic Analysis, OpenAI, Python,\\nSpacy, BERT, NER,AI, Machine Learning, Elastic-search, MongoDB, Flask, API, and Docker.\\nVisiting Faculty\\nMaharashtra institute of Technology • Pune, Maharashtra 08/2019 - 05/2023\\n- 2019:Omkar Kadam\\nkadam.omkar05@gmail.com \\n+91 - 8879891595 \\nPune, MaharashtraDelivering sessions on Microsoft Excel on the following topics: Basic excel, Data formatting, Pivoting, Charts,\\nDashboarding and power-automate for data analysis.\\n- 2021:\\nResponsible for Designing the curriculum for MongoDB, Deep Learning and Matlab for the School of Computer\\nScience.',\n",
              " 'Dashboarding and power-automate for data analysis.\\n- 2021:\\nResponsible for Designing the curriculum for MongoDB, Deep Learning and Matlab for the School of Computer\\nScience.\\nResponsible for designing and Implementing a Project based Learning skills to help imbibe the importance and\\nunderstand the role of persistent system in a Project.\\nSubjects taught : MongoDB , Cloud Services( Google Cloud Platform),Principles of Deep Learning and Introduction\\nto Matlab, Python (core and Advanced), Machine learning (Theory and Practical).\\nData Scientist\\niLink Systems • Pune, Maharashtra 08/2021 - 02/2022\\nPepsiCo\\nCollaborated with a team of 3 to Develop and Deploy Machine learning model using various Clustering\\nTechniques, Regression Models and XGBoost.',\n",
              " 'PepsiCo\\nCollaborated with a team of 3 to Develop and Deploy Machine learning model using various Clustering\\nTechniques, Regression Models and XGBoost.\\nUtilized DataBricks for Data Transformation and H2o.ai for Model Tuning and Optimization.\\nCreated a comprehensive simulated system showcasing the entire workﬂow, skillfully implemented using Flask\\nand Chart.js.\\nResponsible for Framework shifting (PyTorch to TensorFlow)\\nData Analyst\\nZS Associates • Pune, Maharashtra 03/2021 - 07/2021\\nResponsible for Gathering new requirements for introducing a new module in the existing SAP system.\\nPerforming the feasibility check and communicating the client requirements effectively to the developers.\\nPerforming unit testing on the developed module and documenting the performance analysis.',\n",
              " 'Performing the feasibility check and communicating the client requirements effectively to the developers.\\nPerforming unit testing on the developed module and documenting the performance analysis.\\nData Science Consultant\\nNaviya Technology • Pune, Maharashtra 09/2020 - 04/2021\\nResponsible for designing end-to-end analytical solution for the existing organizational workﬂow for better\\nDecision making.\\nIntroduced Tableau software to the company and helped them setup and implemented end to end POC to the\\ndecision makers.\\nAnalyze, cleanse and transform data using Python and SQL in-line with business requirements.\\nEducation\\nMsc (Data Science and Big Data Analytics)\\nMIT World Peace University • Pune, Maharashtra 06/2021',\n",
              " 'Analyze, cleanse and transform data using Python and SQL in-line with business requirements.\\nEducation\\nMsc (Data Science and Big Data Analytics)\\nMIT World Peace University • Pune, Maharashtra 06/2021\\nPublished Research Paper in International Journal of Engineering Research & Technology.\\nMember of Board of Studies - School of Computer Science and Mathematics\\nAdditinal Profiles\\nPublication:\\nTitle : \"A modern approach towards stocks Prediction over Traditional Methods\" Link\\nTableau Proﬁle:\\nTableau Public Proﬁle : Link\\nGitHub: Link LinkedIn : Link\\nCredly: Link\\nLanguagesEnglish, Hindi, Marathi (Mar ā t ̣ h ī )\\nCertifications\\nGoogle Cloud Big Data and Machine Learning Fundamentals - Google Cloud Platform.\\nScalable Machine Learning on Big Data using Apache Spark - IBM',\n",
              " 'Certifications\\nGoogle Cloud Big Data and Machine Learning Fundamentals - Google Cloud Platform.\\nScalable Machine Learning on Big Data using Apache Spark - IBM\\xa0\\nBusiness Statistics and Analysis Specialization - Rice University\\nBig Data Hadoop Professional - C.M.S IT Services']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Two Days workshop on Genera0ve AI   Duration : 14-16 hrs  Workshop Outcomes: • Develop Python programming skills for AI and ML. • Understand Generative Adversarial Networks (GANs) and their role in data generation. • Explore Large Language Models (LLMs) and Natural Language Processing (NLP) for text prediction and understanding. • Create a functional chatbot using the ChatGPT API. • Discover career opportunities in the AI industry. • Clarify doubts through interactive Q&A and reinforce key takeaways.    Course Content  Day 1 :   Session 1: Introduction to Generative AI  • The Fundamentals of Generative AI',\n",
              " '• What is Generative AI? • Key principles and concepts • Applications and Potential • Real-world applications across industries • Opportunities for innovation • DIY Projects and understanding logic behind it  • Text to Video: Transforming text into video content • Text to Music: Creating music from textual input • Text to Website: Generating web content dynamically   Session 2 : Generative Adversarial Networks (GANs)  • What are Generative Adversarial Networks (GANs)?  • The concept of generative modeling • The role of GANs in generating realistic data • Understanding GANs • Architecture of GANs • Training GANs Hands-on Project    Day 2:   Session 1: Deep Dive into Large Language Models (LLMs)',\n",
              " '• Understanding Large Language Models • In-depth exploration of LLMs and their architecture • Their pivotal role in modern AI • Latest Trends and Advancements • Stay updated on cutting-edge developments in LLM research •  Session 2: Text Prediction using LLMs  • Text Prediction Fundamentals • Introduction to text prediction techniques • Use cases and significance • Building a Text Prediction Model • Hands-on development of a text prediction model using LLMs • Training and fine-tuning  Session 3: Building Chatbots with ChatGPT API • Introduction to ChatGPT API • Understanding the capabilities of ChatGPT • API access and authentication  • Crafting Effective ChatGPT Prompts • Strategies for eliciting desired responses • Best practices for interaction • DIY Project',\n",
              " '• Building and customizing a chatbot using the GPT API  Session 4: Industry Insights and Career Opportunities • Current Industry Demands in AI • Understanding the landscape of AI in various sectors • Identifying pressing industry needs • Exploring Career Opportunities • Diverse roles and career paths in AI • Skills and qualifications required  Session 5: Q&A and Recap • Interactive Q&A • An open forum for participants to ask questions  • Clarification on any workshop topics • Key Takeaways Recap • Summarize and reinforce the main points from the workshop']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wqy4vJhrSXUT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/omkar/miniconda3/envs/gpt/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3igYiWjISjvS"
      },
      "outputs": [],
      "source": [
        "document_search = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bJpE1qlSlNb",
        "outputId": "2eebaa45-b187-4f57-da0e-625940ae5754"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain.vectorstores.faiss.FAISS at 0x147d84cd0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Po-ip1fPSonv"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iYl2PzKSSqg0"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "GQafhpOz4IsV",
        "outputId": "b05ede70-3d69-40ee-a4af-ba0bd14659b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Session 2 of the Two Days Workshop on Generative AI consists of Deep Dive into Large Language Models (LLMs) and Text Prediction using LLMs.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \" what is session 2 consist of\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7sjc1Xh2SsTs",
        "outputId": "2c3ef36a-4732-4f54-d704-eda850c292a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The agriculture credit target will be increased to ` 20 lakh crore with focus on animal husbandry, dairy and fisheries.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How much the agriculture target will be increased to and what the focus will be\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fo7RaEjjt9u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
